{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0d0e65",
   "metadata": {},
   "source": [
    "# Create synethetic dataset\n",
    "\n",
    "(To showcase file structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84203f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating a synthetic fMRI dataset for Brain-Semantoks model\n",
    "\n",
    "# This cell demonstrates how to create a properly formatted HDF5 dataset \n",
    "# that can be used with the Brain-Semantoks model for pretraining or \n",
    "# downstream tasks (linear probe/finetuning).\n",
    "\n",
    "# Dataset requirements:\n",
    "# - TR = 2.0 seconds (0.5 Hz sampling rate)\n",
    "# - ROI ordering: 7-network ordering for Schaefer400 parcellation (THIS IS DIFFERENT FROM SOME OTHER MODELS! The ROIs are the same for 7n and 17n, but the ordering is different.)\n",
    "# See: https://github.com/ThomasYeoLab/CBIG/tree/v0.14.3-Update_Yeo2011_Schaefer2018_labelname/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal/Parcellations/MNI/\n",
    "# - Z-score normalization per ROI per subject\n",
    "# - Bandpass filtering: 0.01-0.1 Hz (similar filters like 0.009-0.08 are fine too. Some small tests indicate unfiltered data works almost as well.)\n",
    "# - HDF5 file structure matching the expected format\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy import signal\n",
    "\n",
    "def bandpass_filter(data, lowcut=0.01, highcut=0.1, fs=0.5, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    \n",
    "    filtered_data = np.zeros_like(data)\n",
    "    for i in range(data.shape[0]):  # for each subject\n",
    "        for j in range(data.shape[1]):  # for each ROI\n",
    "            filtered_data[i, j, :] = signal.filtfilt(b, a, data[i, j, :])\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "def zscore_per_roi(data):\n",
    "    zscored = np.zeros_like(data)\n",
    "    for i in range(data.shape[0]):  # for each subject\n",
    "        for j in range(data.shape[1]):  # for each ROI\n",
    "            roi_ts = data[i, j, :]\n",
    "            zscored[i, j, :] = (roi_ts - roi_ts.mean()) / (roi_ts.std() + 1e-8)\n",
    "    \n",
    "    return zscored\n",
    "\n",
    "# Create synthetic dataset\n",
    "n_subjects = 20\n",
    "n_timepoints = 180  # TR=2.0, so 180 TRs = 6 minutes\n",
    "n_rois_schaefer = 400\n",
    "n_rois_tian = 50\n",
    "n_rois_buckner = 7\n",
    "\n",
    "# Generate random timeseries data N(0,1) for each atlas\n",
    "print(\"Generating synthetic timeseries...\")\n",
    "schaefer_data = np.random.randn(n_subjects, n_rois_schaefer, n_timepoints)\n",
    "tian_data = np.random.randn(n_subjects, n_rois_tian, n_timepoints)\n",
    "buckner_data = np.random.randn(n_subjects, n_rois_buckner, n_timepoints)\n",
    "\n",
    "# Apply bandpass filter (0.01-0.1 Hz, TR=2.0 -> fs=0.5 Hz)\n",
    "print(\"Applying bandpass filter (0.01-0.1 Hz)...\")\n",
    "schaefer_data = bandpass_filter(schaefer_data, lowcut=0.01, highcut=0.1, fs=0.5)\n",
    "tian_data = bandpass_filter(tian_data, lowcut=0.01, highcut=0.1, fs=0.5)\n",
    "buckner_data = bandpass_filter(buckner_data, lowcut=0.01, highcut=0.1, fs=0.5)\n",
    "\n",
    "# Z-score per ROI per subject\n",
    "print(\"Z-scoring per ROI per subject...\")\n",
    "schaefer_data = zscore_per_roi(schaefer_data)\n",
    "tian_data = zscore_per_roi(tian_data)\n",
    "buckner_data = zscore_per_roi(buckner_data)\n",
    "\n",
    "# Create subject IDs\n",
    "subject_ids = np.array([f'sub-SYNTHETIC{i:05d}'.encode('utf-8') for i in range(n_subjects)])\n",
    "\n",
    "# Create labels for downstream tasks\n",
    "# Age: 5 classes (binned)\n",
    "age_5c = np.random.randint(0, 5, size=n_subjects)\n",
    "\n",
    "# Sex: binary\n",
    "sex_bi = np.random.randint(0, 2, size=n_subjects)\n",
    "\n",
    "# Continuous age\n",
    "age = np.random.uniform(18, 80, size=n_subjects)\n",
    "\n",
    "print(\"\\nDataset shapes:\")\n",
    "print(f\"  Schaefer400: {schaefer_data.shape}\")\n",
    "print(f\"  Tian subcortical: {tian_data.shape}\")\n",
    "print(f\"  Buckner7: {buckner_data.shape}\")\n",
    "print(f\"  Subject IDs: {subject_ids.shape}\")\n",
    "print(f\"  Labels (age_5c): {age_5c.shape}\")\n",
    "print(f\"  Labels (sex_bi): {sex_bi.shape}\")\n",
    "\n",
    "# Save to HDF5 file\n",
    "output_path = \"/home/sagi11/code/Brain-Semantoks/synthetic_dataset_example.h5\"\n",
    "print(f\"\\nSaving to: {output_path}\")\n",
    "\n",
    "with h5py.File(output_path, 'w') as f:\n",
    "    # Create timeseries group\n",
    "    ts_group = f.create_group('timeseries')\n",
    "    \n",
    "    # Store each atlas separately (following 7n ordering for Schaefer400); fp16 is safe given z-scoring\n",
    "    ts_group.create_dataset('schaefer400', data=schaefer_data.astype(np.float16), compression='gzip')\n",
    "    ts_group.create_dataset('tian3', data=tian_data.astype(np.float16), compression='gzip')\n",
    "    ts_group.create_dataset('buckner7', data=buckner_data.astype(np.float16), compression='gzip')\n",
    "    \n",
    "    # Store subject identifiers\n",
    "    f.create_dataset('long_subject_id', data=subject_ids)\n",
    "    \n",
    "    # Store labels for downstream tasks\n",
    "    f.create_dataset('age_5c', data=age_5c)\n",
    "    f.create_dataset('sex_bi', data=sex_bi)\n",
    "    f.create_dataset('age', data=age)\n",
    "    \n",
    "\n",
    "# Verify the saved file\n",
    "with h5py.File(output_path, 'r') as f:\n",
    "    print(f\"Top-level keys: {list(f.keys())}\")\n",
    "    print(f\"Timeseries keys: {list(f['timeseries'].keys())}\")\n",
    "    print(f\"\\nShapes:\")\n",
    "    print(f\"  schaefer400: {f['timeseries/schaefer400'].shape}\")\n",
    "    print(f\"  tian3: {f['timeseries/tian3'].shape}\")\n",
    "    print(f\"  buckner7: {f['timeseries/buckner7'].shape}\")\n",
    "    print(f\"  long_subject_id: {f['long_subject_id'].shape}\")\n",
    "    print(f\"\\nFirst 5 subject IDs: {f['long_subject_id'][:5]}\")\n",
    "\n",
    "# To use this dataset in config YAML files:\n",
    "\n",
    "# For pretraining (specify in data.datasets):\n",
    "#   - name: synthetic\n",
    "#     data_path: /path/to/synthetic_dataset_example.h5\n",
    "#     raw_signal_length: 180\n",
    "#     train_subject_ids_path: /path/to/train_subject_ids.npy  # optional\n",
    "\n",
    "# For downstream tasks (linear_probe.probe_datasets or finetune.probe_datasets):\n",
    "#   - name: synthetic_age\n",
    "#     data_path: /path/to/synthetic_dataset_example.h5\n",
    "#     label_names: ['age_5c']\n",
    "#     n_class: [5]\n",
    "#     raw_signal_length: 180\n",
    "#     probe_train_subject_ids_path: /path/to/subject_ids.npy  # optional\n",
    "#     split_ratio: [0.7, 0.15, 0.15]  # train, val, test\n",
    "#     stratify: ['age_5c']\n",
    "\n",
    "#   - name: synthetic_sex  \n",
    "#     data_path: /path/to/synthetic_dataset_example.h5\n",
    "#     label_names: ['sex_bi']\n",
    "#     n_class: [2]\n",
    "#     raw_signal_length: 180\n",
    "#     split_ratio: [0.7, 0.15, 0.15]\n",
    "#     stratify: ['sex_bi']\n",
    "\n",
    "# The model expects concatenated timeseries in this order:\n",
    "#   [schaefer400, tian3, buckner7] -> total 457 ROIs\n",
    "  \n",
    "# With target_signal_length=100, the model processes 100-timepoint crops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92e631a",
   "metadata": {},
   "source": [
    "# Use model to obtain data representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from simdino import SimDINOModel\n",
    "\n",
    "class ModelInferenceWrapper:    \n",
    "    def __init__(self, cfg, device='cuda'):\n",
    "        \"\"\"\n",
    "        Initialize model from config file.\n",
    "        \n",
    "        Args:\n",
    "            config_path: Path to YAML config file (with resume_checkpoint path)\n",
    "            device: 'cuda' or 'cpu'\n",
    "        \"\"\"\n",
    "        self.device = torch.device(device)\n",
    "        self.config = cfg\n",
    "\n",
    "        model_cfg = self.config['model']\n",
    "        data_cfg = self.config['data']\n",
    "        dino_cfg = self.config['dino']\n",
    "        ssl_cfg = self.config['ssl']\n",
    "        \n",
    "        checkpoint_path = self.config['training'].get('resume_checkpoint')\n",
    "        if not checkpoint_path or not os.path.exists(checkpoint_path):\n",
    "            raise ValueError(f\"Checkpoint not found at: {checkpoint_path}\")\n",
    "        print(f\"Checkpoint path: {checkpoint_path}\")\n",
    "                \n",
    "        # Build atlas names from explicit config\n",
    "        atlas_names = []\n",
    "        atlas_network_counts = []\n",
    "        total_rois = 0\n",
    "        for atlas_type in ['schaefer', 'tian', 'buckner']:\n",
    "            atlas_name = data_cfg.get(f'{atlas_type}_atlas')\n",
    "            if atlas_name is not None:\n",
    "                atlas_names.append(atlas_name)\n",
    "                atlas_network_counts.append(data_cfg[f'{atlas_type}_networks'])\n",
    "                total_rois += data_cfg[f'{atlas_type}_rois']\n",
    "        \n",
    "        max_spatial = data_cfg.get('max_spatial', False)\n",
    "        min_spatial = data_cfg.get('min_spatial', False)\n",
    "    \n",
    "        mlp_dim = int(model_cfg['embedding_dim'] * 4)\n",
    "        heads = int(model_cfg['embedding_dim'] / 64)\n",
    "        \n",
    "        self.model = SimDINOModel(\n",
    "            patch_size=data_cfg['patch_size'],\n",
    "            do_masking=True,\n",
    "            target_time_length=data_cfg['target_signal_length'],\n",
    "            embedding_dim=model_cfg['embedding_dim'],\n",
    "            depth=model_cfg['depth'],\n",
    "            mlp_dim=mlp_dim,\n",
    "            heads=heads,\n",
    "            global_pooling=model_cfg['global_pooling'],\n",
    "            layer_scale_init_value=model_cfg.get('layer_scale_init_value', None),\n",
    "            network_data_path=data_cfg['network_map_path'],\n",
    "            atlas_names=atlas_names,\n",
    "            projection_hidden_dim=model_cfg['projection_hidden_dim'],\n",
    "            projection_bottleneck_dim=model_cfg['projection_bottleneck_dim'],\n",
    "            projection_nlayers=model_cfg['projection_nlayers'],\n",
    "            base_teacher_momentum=dino_cfg['base_teacher_momentum'],\n",
    "            coeff=dino_cfg['coeff'],\n",
    "            mask_loss_weight=ssl_cfg['mask_loss_weight'],\n",
    "            network_loss_weight=ssl_cfg.get('network_loss_weight', 0.0),\n",
    "            backbone_type=model_cfg.get('backbone_type', 'cnn_tf'),\n",
    "            # semantoks_config=model_cfg.get('semantoks_config', None),\n",
    "            max_spatial=max_spatial,\n",
    "            min_spatial=min_spatial,\n",
    "            total_rois=total_rois,\n",
    "            atlas_network_counts=atlas_network_counts,\n",
    "            tokenizer_config=model_cfg.get('tokenizer', {}).get('config'),\n",
    "            tokenizer_final_norm=model_cfg.get('tokenizer', {}).get('final_norm', 'layer')\n",
    "        )\n",
    "        \n",
    "        # Load checkpoint weights\n",
    "        print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "        \n",
    "        if list(state_dict.keys())[0].startswith('module.'):\n",
    "            state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "        \n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        print(\"Model loaded successfully\")\n",
    "        print(f\"  Embedding dimension: {model_cfg['embedding_dim']}\")\n",
    "    \n",
    "    def extract_embeddings(self, data, atlas_idx=0, feature_type='cls_avg', \n",
    "                          use_teacher=True, return_dict=False):\n",
    "        \"\"\"\n",
    "        Extract embeddings from fMRI data.\n",
    "        \n",
    "        Args:\n",
    "            data: Input tensor of shape (batch, channels, time)\n",
    "                  e.g., (32, 400, 100) for Schaefer400 atlas\n",
    "            atlas_idx: Which atlas to use (0 for first atlas in config)\n",
    "            feature_type: Type of features to extract:\n",
    "                - 'cls': CLS token only\n",
    "                - 'avg': Average of all tokens (excluding CLS)\n",
    "                - 'cls_avg': Concatenation of CLS and averaged tokens\n",
    "            use_teacher: Use teacher encoder (True) or student encoder (False)\n",
    "            return_dict: If True, return full output dict; if False, return features only\n",
    "        \n",
    "        Returns:\n",
    "            embeddings: Tensor of shape (batch, feature_dim)\n",
    "                - feature_dim = embedding_dim for 'cls' or 'avg'\n",
    "                - feature_dim = embedding_dim * 2 for 'cls_avg'\n",
    "            OR dict with keys ['global_cls', 'tokens'] if return_dict=True\n",
    "        \"\"\"\n",
    "        if isinstance(data, np.ndarray):\n",
    "            data = torch.from_numpy(data).float()\n",
    "        \n",
    "        data = data.to(self.device)\n",
    "        if data.ndim == 2:\n",
    "            data = data.unsqueeze(0) \n",
    "                \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            encoder = self.model.teacher_encoder if use_teacher else self.model.student_encoder\n",
    "            \n",
    "            output = encoder(data, atlas=atlas_idx, mask=None)\n",
    "            \n",
    "            if return_dict:\n",
    "                return output\n",
    "            \n",
    "            # Extract features based on type\n",
    "            if feature_type == 'cls':\n",
    "                features = output['global_cls']\n",
    "            elif feature_type == 'avg':\n",
    "                features = output['tokens'][:, 1:].mean(dim=1)\n",
    "            elif feature_type == 'cls_avg':\n",
    "                avg_tokens = output['tokens'][:, 1:].mean(dim=1)\n",
    "                features = torch.cat([avg_tokens, output['global_cls']], dim=1)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown feature_type: {feature_type}. \"\n",
    "                               f\"Use 'cls', 'avg', or 'cls_avg'\")\n",
    "            \n",
    "            return features\n",
    "    \n",
    "    def extract_embeddings_batch(self, data_loader, **kwargs):\n",
    "        all_embeddings = []\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            if isinstance(batch, dict):\n",
    "                data = batch['signal'][0][0]  \n",
    "            else:\n",
    "                data = batch\n",
    "            \n",
    "            embeddings = self.extract_embeddings(data, **kwargs)\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "        \n",
    "        return torch.cat(all_embeddings, dim=0)\n",
    "    \n",
    "    def get_feature_dim(self, feature_type='cls_avg'):\n",
    "        \"\"\"Get the dimensionality of extracted features.\"\"\"\n",
    "        base_dim = self.config['model']['embedding_dim']\n",
    "        if feature_type == 'cls_avg':\n",
    "            return base_dim * 2\n",
    "        else:\n",
    "            return base_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75091d6d",
   "metadata": {},
   "source": [
    "Download the model from: https://huggingface.co/SamGijsen/Brain-Semantoks\n",
    "\n",
    "Then, fill in the path to the config and checkpoint files below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tbf7o9k8dwn",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = 'path/to/downloaded/config_used.yaml'\n",
    "ckpt_path = 'path/to/downloaded/brainsemantoks_ckpt_epoch_100.pth'\n",
    "\n",
    "\n",
    "cfg = yaml.safe_load(open(cfg_path, 'r'))\n",
    "cfg[\"training\"][\"resume_checkpoint\"] = ckpt_path\n",
    "cfg[\"data\"][\"network_map_path\"] = './network_mapping.npz'\n",
    "\n",
    "model_wrapper = ModelInferenceWrapper(\n",
    "    cfg=cfg,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "# Load and concatenate timeseries from synthetic dataset\n",
    "with h5py.File(\"synthetic_dataset_example.h5\", 'r') as f:\n",
    "    data = np.concatenate([\n",
    "        f['timeseries/schaefer400'][:],\n",
    "        f['timeseries/tian3'][:],\n",
    "        f['timeseries/buckner7'][:]\n",
    "    ], axis=1)\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")  # (n_subjects, 457 ROIs, n_timepoints)\n",
    "\n",
    "# Extract cls_avg embeddings (model expects 100 timepoints, but see the task-based fMRI application in our paper if you'd like to use the model for shorter sequence, blocks, or trials!)\n",
    "embeddings = model_wrapper.extract_embeddings(\n",
    "    data[:, :, :100],  # first 100 timepoints\n",
    "    feature_type='cls_avg',\n",
    "    use_teacher=True\n",
    ")\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")  # (n_subjects, 1536)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
